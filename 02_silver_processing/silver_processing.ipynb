{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45d73608-74cf-403c-ba88-fe344f456579",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ðŸ“„ Patient Readmission Feature Engineering (Bronze â†’ Silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "52293786-a1f2-4dd2-8595-4706e15687df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load bronze layer table into DataFrame for initial exploration\n",
    "\n",
    "bronze_df = spark.read.table(\"bronze_patient_readmission\")\n",
    "bronze_df.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e39abca-6177-42df-aa17-0cc5c7cf8b8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create binary feature 'readmit_30d' (1 if readmitted within 30 days, else 0)\n",
    "\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "silver_df = bronze_df.withColumn(\n",
    "    \"readmit_30d\",\n",
    "    when(col(\"readmitted\") == \"<30\", 1).otherwise(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d8deed4-2ac6-49e2-b9f0-38828d6b88da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop leakage columns that could cause data leakage in ML models\n",
    "\n",
    "leakage_cols = [\"readmitted\", \"encounter_id\", \"patient_nbr\"]\n",
    "silver_df = silver_df.drop(*leakage_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08a60361-4151-49d2-b0e1-291a4fd8a216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Handle missing values by filling nulls with 'Unknown'\n",
    "\n",
    "silver_df = silver_df.fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "105946dd-8dab-4063-8745-ce60a079c169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create age buckets (Young, Middle, Senior) for categorical grouping\n",
    "\n",
    "silver_df = silver_df.withColumn(\n",
    "    \"age_bucket\",\n",
    "    when(col(\"age\").isin(\"[0-10]\", \"[10-20]\", \"[20-30]\"), \"Young\")\n",
    "    .when(col(\"age\").isin(\"[30-40]\", \"[40-50]\", \"[50-60]\"), \"Middle\")\n",
    "    .otherwise(\"Senior\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3736aa4d-15a8-41ca-8035-8e4da664597d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compute utilization score as sum of inpatient, emergency, and outpatient visits\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "silver_df = silver_df.withColumn(\n",
    "    \"utilization_score\",\n",
    "    expr(\"number_inpatient + number_emergency + number_outpatient\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d741667-f6de-4abb-b40d-bb5dac73f493",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create binary feature 'treatment_changed' (1 if treatment changed, else 0)\n",
    "\n",
    "silver_df = silver_df.withColumn(\n",
    "    \"treatment_changed\",\n",
    "    when(col(\"change\") == \"Ch\", 1).otherwise(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "600275de-880a-4765-b725-d7a74f569b91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS silver_patient_features;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3caf82b6-395f-4211-a925-6be13ae5fb8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# -------------------------\n",
    "# Create treatment_changed\n",
    "# -------------------------\n",
    "silver_df = silver_df.withColumn(\n",
    "    \"treatment_changed\",\n",
    "    when(col(\"change\") == \"Ch\", 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Save clean Silver table\n",
    "# -------------------------\n",
    "silver_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"silver_patient_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de7a7765-f6e8-40da-b77e-90abc612bdfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Validate Silver table: count total rows and number of high-risk patients\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS total_rows,\n",
    "  SUM(readmit_30d) AS high_risk_patients\n",
    "FROM silver_patient_features\n",
    "\"\"\").display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b9394f7-6ede-4f80-b172-98b5545eb479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SILVER â€“ LOAD BRONZE\n",
    "# =========================\n",
    "\n",
    "df = spark.table(\"default.bronze_patient_readmission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "669509eb-9355-44f5-86b3-c52e043e72a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Define df by reading the table\n",
    "df = spark.table(\"default.bronze_patient_readmission\")\n",
    "\n",
    "df_silver = (\n",
    "    df\n",
    "    # # Create binary flag: 1 if readmitted within 30 days, else 0\n",
    "    .withColumn(\n",
    "        \"readmit_30d\",\n",
    "        when(col(\"readmitted\") == \"<30\", 1).otherwise(0)\n",
    "    )\n",
    "    # # Cast inpatient visits column to integer\n",
    "    .withColumn(\n",
    "        \"number_inpatient\",\n",
    "        col(\"number_inpatient\").cast(\"int\")\n",
    "    )\n",
    "    # # Cast emergency visits column to integer\n",
    "    .withColumn(\n",
    "        \"number_emergency\",\n",
    "        col(\"number_emergency\").cast(\"int\")\n",
    "    )\n",
    "    # # Cast outpatient visits column to integer\n",
    "    .withColumn(\n",
    "        \"number_outpatient\",\n",
    "        col(\"number_outpatient\").cast(\"int\")\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b76f5ab-69a8-4e80-861d-1e40838d008b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Create utilization_score to measure overall healthcare usage by summing inpatient, emergency, and outpatient visits\n",
    "\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"utilization_score\",\n",
    "    col(\"number_inpatient\")\n",
    "    + col(\"number_emergency\")\n",
    "    + col(\"number_outpatient\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2acdb72c-5eb9-406e-8f3d-f9aad577e3b4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Silver DataFrame to Delta Table (fixed)"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%sql\n",
    "DROP TABLE IF EXISTS default.silver_patient_features;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc492bf2-4773-4395-8d06-3525ca27163d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Cast number_outpatient column to integer for proper numeric analysis and calculations\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_silver_fixed = (\n",
    "    df_silver\n",
    "    .withColumn(\"number_outpatient\", col(\"number_outpatient\").cast(\"int\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45577590-596f-4b6d-8d3c-cb825c58634c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Save the transformed DataFrame as a managed table, overwriting old data and schema if needed\n",
    "\n",
    "\n",
    "\n",
    "(\n",
    "    df_silver_fixed\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(\"default.silver_patient_features\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aa01329-3d5f-43d5-932f-90706d0d1025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE TABLE default.silver_patient_features;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7190408177278843,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
