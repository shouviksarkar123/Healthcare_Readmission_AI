{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0533d17a-0a18-4b79-8d10-7c4e80efde65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## This notebook applies machine learning to identify patients at high risk of 30-day hospital readmission, enabling proactive care decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "671660f2-9a44-4279-9c47-5151a6b50a4e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769538351962}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load ML-ready Gold data\n",
    "df = spark.read.table(\"gold_patient_features\")\n",
    "df.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e71b5752-94e0-4582-b823-882ec357e125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import MLflow, Pandas, and Scikit-learn libraries for model training and evaluation\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f13f9ca8-c1c0-46c1-99cb-004c49b09723",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set MLflow experiment path for readmission prediction runs\n",
    "\n",
    "mlflow.set_experiment(\"/Shared/readmission_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17404277-0afa-4a38-80b1-4137a406ba63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load gold_patient_features table into Spark DataFrame and convert to Pandas\n",
    "\n",
    "df_spark = spark.table(\"default.gold_patient_features\")\n",
    "df = df_spark.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b997b17-6a2a-4ba9-815d-afc759a8ab12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split dataset into features (X) and target (y) for readmission prediction\n",
    "\n",
    "TARGET_COL = \"readmit_30d\"\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee7ef70c-b3bf-4ce5-aeee-1dd858a16c03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets with stratified sampling\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70bb9c7f-4faf-417f-9c70-046ca8345ebb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 8"
    }
   },
   "outputs": [],
   "source": [
    "# üîç HARD DEBUG CHECK (RUN THIS FIRST)\n",
    "\n",
    "print(\"Table exists:\", spark.catalog.tableExists(\"default.gold_patient_features\"))\n",
    "\n",
    "df = spark.read.table(\"default.gold_patient_features\")\n",
    "\n",
    "print(\"Total rows:\", df.count())\n",
    "print(\"Columns:\", df.columns)\n",
    "\n",
    "df.select(\"utilization_score\", \"treatment_changed\", \"readmit_30d\") \\\n",
    "  .summary(\"count\") \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb90bb15-2b87-4730-8b9d-8a1b2a42c52c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# -------------------------\n",
    "# 1Ô∏è‚É£ Load GOLD table\n",
    "# -------------------------\n",
    "df_gold = spark.read.table(\"default.gold_patient_features\")\n",
    "\n",
    "# -------------------------\n",
    "# 2Ô∏è‚É£ SAFE DATA PREP (NO dropna)\n",
    "# -------------------------\n",
    "df_ml = (\n",
    "    df_gold\n",
    "    .select(\"utilization_score\", \"treatment_changed\", \"readmit_30d\")\n",
    "    .fillna({\n",
    "        \"utilization_score\": 0,\n",
    "        \"treatment_changed\": 0,\n",
    "        \"readmit_30d\": 0\n",
    "    })\n",
    ")\n",
    "\n",
    "row_count = df_ml.count()\n",
    "print(\"Rows available for ML:\", row_count)\n",
    "\n",
    "if row_count < 20:\n",
    "    raise Exception(f\"‚ùå Still not enough rows for ML training: {row_count}\")\n",
    "\n",
    "# -------------------------\n",
    "# 3Ô∏è‚É£ Convert to Pandas\n",
    "# -------------------------\n",
    "pdf = df_ml.toPandas()\n",
    "\n",
    "X = pdf[[\"utilization_score\", \"treatment_changed\"]]\n",
    "y = pdf[\"readmit_30d\"]\n",
    "\n",
    "# -------------------------\n",
    "# 4Ô∏è‚É£ Train/Test split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 5Ô∏è‚É£ MLflow Training\n",
    "# -------------------------\n",
    "mlflow.set_experiment(\"/Shared/readmission_prediction\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    model = LogisticRegression(max_iter=300)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    mlflow.log_param(\"model\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"features\", \"utilization_score, treatment_changed\")\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "\n",
    "    mlflow.sklearn.log_model(model, \"readmission_model\")\n",
    "\n",
    "    print(\"‚úÖ MODEL TRAINED SUCCESSFULLY\")\n",
    "    print(\"Accuracy:\", round(acc, 4))\n",
    "    print(\"AUC:\", round(auc, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e61a2866-cda4-4379-89ab-c2ebd62dc880",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Drop NaNs before model training"
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in features and target\n",
    "X = X.dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# Continue with train/test split and model training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3f2c5d0-a5db-41b7-9784-ddbe7110618e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print schema of gold_patient_features table\n",
    "\n",
    "spark.table(\"default.gold_patient_features\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "777a33e2-5c32-4257-8d1d-adae962e9de3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select key columns for modeling and analysis\n",
    "\n",
    "selected_cols = [\n",
    "    \"utilization_score\",\n",
    "    \"readmit_30d\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ml_readmission_prediction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
